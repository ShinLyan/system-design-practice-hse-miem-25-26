# HW3 – PostgreSQL High Availability с Patroni

Шин В.А. МКС244

## 1. Архитектура кластера

В рамках домашнего задания был развернут отказоустойчивый кластер PostgreSQL с использованием следующего стека:
- PostgreSQL – основная СУБД
- Patroni – менеджер PostgreSQL-кластера
- etcd – Distributed Configuration Store
- HAProxy – прокси для клиентских подключений

Кластер состоит из:
- 3 нод PostgreSQL + Patroni
- 3 нод etcd
- 1 HAProxy

Цель архитектуры – устранение единой точки отказа и автоматическое переключение лидера при сбоях.

## 2. Роли компонентов

### PostgreSQL и Patroni

Patroni запущен рядом с каждым экземпляром PostgreSQL и отвечает за мониторинг состояния БД, взаимодействие с etcd, выбор лидера и переключение ролей нод.

Каждый экземпляр Patroni пытается захватить лидерский ключ в etcd. Нода, владеющая ключом, становится лидером, остальные переводятся в режим реплик.

### etcd

etcd используется как распределённое хранилище конфигурации. В нём хранится информация о состоянии кластера и текущем лидере.

etcd работает на алгоритме Raft, поэтому для его функционирования необходим кворум. При потере кворума Patroni не может выполнять failover.

### HAProxy

HAProxy используется как единая точка входа для клиентских приложений. Он опрашивает REST API Patroni и перенаправляет трафик на актуального лидера.

Клиенту не требуется знать адреса конкретных серверов базы данных.

## 3. Состояние кластера

С помощью команды:

```bash
patronictl list
```

было подтверждено наличие одного лидера и нескольких реплик, все ноды находятся в состоянии `running`.

Через веб-интерфейс HAProxy (`http://localhost:7001/`) отображается текущее состояние backend-серверов и активного лидера.

## 4. Работа с данными

Через подключение к лидеру и репликам был выполнен SQL-скрипт, в результате которого:
- созданы таблицы `owners` и `events`
- настроены внешние ключи и индексы
- добавлены тестовые данные

После этого был запущен скрипт `traffic-generator.py`, который периодически выполняет операции записи и чтения.

Записи выполняются через лидера, чтения могут выполняться с реплик. Данные корректно реплицируются между всеми нодами.

## 5. Проверка отказоустойчивости

### Остановка реплики

При остановке одной из реплик кластер продолжает работать, лидер не меняется, приложение продолжает читать и писать данные.

### Остановка лидера

При остановке ноды-лидера Patroni фиксирует отказ и выполняет автоматический failover. Одна из реплик становится новым лидером, HAProxy перенаправляет трафик, приложение продолжает работу с кратковременной паузой.

### Остановка ноды etcd

При остановке одной ноды etcd кворум сохраняется, кластер продолжает работать.

При остановке большинства нод etcd кворум теряется, Patroni не может принимать решения, новые failover невозможны, текущее состояние кластера сохраняется.

### Остановка HAProxy

При остановке HAProxy клиентское приложение теряет доступ к БД, при этом PostgreSQL и Patroni продолжают работать.

В данной конфигурации HAProxy является единой точкой отказа. В production-решениях это устраняется использованием нескольких прокси и механизмов failover.

## 6. Наблюдения в Grafana

В Grafana отображаются метрики загрузки CPU и памяти PostgreSQL, репликационный лаг и состояние инстансов Patroni.

Метрики подтверждают корректную репликацию и автоматическое переключение лидера.

## 7. Выводы

В ходе выполнения работы был развернут и протестирован отказоустойчивый кластер PostgreSQL с использованием Patroni.

Основные выводы:
- Patroni устраняет SPOF PostgreSQL за счёт автоматического failover
- etcd является критическим компонентом для управления кластером
- HAProxy упрощает работу клиентов, но сам может стать SPOF
- кластер корректно переживает отказ реплик и лидера
- архитектура соответствует принципам отказоустойчивых распределённых систем
